"use strict";(self.webpackChunkdagger=self.webpackChunkdagger||[]).push([[1204],{3905:function(e,t,n){n.d(t,{Zo:function(){return u},kt:function(){return c}});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var p=a.createContext({}),s=function(e){var t=a.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},u=function(e){var t=s(e.components);return a.createElement(p.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,p=e.parentName,u=i(e,["components","mdxType","originalType","parentName"]),d=s(n),c=r,h=d["".concat(p,".").concat(c)]||d[c]||m[c]||o;return n?a.createElement(h,l(l({ref:t},u),{},{components:n})):a.createElement(h,l({ref:t},u))}));function c(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,l=new Array(o);l[0]=d;var i={};for(var p in t)hasOwnProperty.call(t,p)&&(i[p]=t[p]);i.originalType=e,i.mdxType="string"==typeof e?e:r,l[1]=i;for(var s=2;s<o;s++)l[s]=n[s];return a.createElement.apply(null,l)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},4251:function(e,t,n){n.r(t),n.d(t,{contentTitle:function(){return p},default:function(){return d},frontMatter:function(){return i},metadata:function(){return s},toc:function(){return u}});var a=n(7462),r=n(3366),o=(n(7294),n(3905)),l=["components"],i={},p="Post Processors",s={unversionedId:"advance/post_processor",id:"advance/post_processor",isDocsHomePage:!1,title:"Post Processors",description:"Post Processors give the capability to do custom stream processing after the SQL processing is performed. Complex transformation, enrichment & aggregation use cases are difficult to execute & maintain using SQL. Post Processors solve this problem through code and/or configuration. This can be used to enrich the stream from external sources (HTTP, ElasticSearch, PostgresDB, GRPC), enhance data points using function or query and transform through user-defined code.",source:"@site/docs/advance/post_processor.md",sourceDirName:"advance",slug:"/advance/post_processor",permalink:"/dagger/docs/advance/post_processor",editUrl:"https://github.com/odpf/dagger/edit/master/docs/docs/advance/post_processor.md",tags:[],version:"current",frontMatter:{},sidebar:"docsSidebar",previous:{title:"Pre Processors",permalink:"/dagger/docs/advance/pre_processor"},next:{title:"Longbow",permalink:"/dagger/docs/advance/longbow"}},u=[{value:"External Post Processor",id:"external-post-processor",children:[{value:"<strong>Elasticsearch</strong>",id:"elasticsearch",children:[]},{value:"<strong>HTTP</strong>",id:"http",children:[]},{value:"<strong>Postgres</strong>",id:"postgres",children:[]},{value:"<strong>GRPC</strong>",id:"grpc",children:[]}]},{value:"Internal Post Processor",id:"internal-post-processor",children:[{value:"Workflow",id:"workflow-4",children:[]},{value:"Configuration",id:"configuration-4",children:[]},{value:"Sample Query",id:"sample-query-4",children:[]},{value:"Sample Configurations",id:"sample-configurations",children:[]}]},{value:"Transformers",id:"transformers",children:[]},{value:"Number of Post Processors",id:"number-of-post-processors",children:[]},{value:"Throughput",id:"throughput",children:[]},{value:"Output Proto",id:"output-proto",children:[]},{value:"Connectivity",id:"connectivity",children:[]}],m={toc:u};function d(e){var t=e.components,i=(0,r.Z)(e,l);return(0,o.kt)("wrapper",(0,a.Z)({},m,i,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"post-processors"},"Post Processors"),(0,o.kt)("p",null,"Post Processors give the capability to do custom stream processing after the SQL processing is performed. Complex transformation, enrichment & aggregation use cases are difficult to execute & maintain using SQL. Post Processors solve this problem through code and/or configuration. This can be used to enrich the stream from external sources (HTTP, ElasticSearch, PostgresDB, GRPC), enhance data points using function or query and transform through user-defined code."),(0,o.kt)("p",null,"All the post processors mentioned in this doc can be applied in a sequential manner, which enables you to get information from multiple different external data sources and apply as many transformers as required. The output of one processor will be the input for the other and the final result will be pushed to the configured sink."),(0,o.kt)("h1",{id:"flow-of-execution"},"Flow of Execution"),(0,o.kt)("p",null,"In the flow of Post Processors, all types of processors viz; External Post Processors, Internal Post Processors and Transformers can be applied sequentially via config. The output of one Post Processor will be the input of the next one. The input SQL is executed first before any of the Post Processors and the Post Processors run only on the output of the SQL. Here is an example of a simple use case that can be solved using Post Processor and sample Data flow Diagrams for that."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Let's assume that you want to find cashback given for a particular order number from an external API endpoint. You can use an ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#http"},"HTTP external post-processor")," for this. Here is a basic Data flow diagram.")),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(3862).Z})),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"In the above example, assume you also want to output the information of customer_id and amount which are fields from input proto. ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#internal-post-processor"},"Internal Post Processor")," can be used for selecting these fields from the input stream.")),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(3471).Z})),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"After getting customer_id, amount and cashback amount, you may want to round off the cashback amount. For this, you can write a custom ",(0,o.kt)("a",{parentName:"p",href:"/dagger/docs/guides/use_transformer"},"transformer")," which is a simple Java Flink Map function to calculate the round-off amount."),(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Note:")," All the above processors are chained sequentially on the output of the previous processor. The order of execution is determined via the order provided in JSON config."))),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(4684).Z})),(0,o.kt)("h1",{id:"types-of-post-processors"},"Types of Post Processors"),(0,o.kt)("p",null,"There are three types of Post Processors :"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#external-post-processor"},"External Post Processor")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#internal-post-processor"},"Internal Post Processor")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#transformers"},"Transformers"))),(0,o.kt)("p",null,"Post Processors are entirely configuration driven. All the Post Processor related configs should be configured as part of ",(0,o.kt)("a",{parentName:"p",href:"/dagger/docs/reference/configuration#processor_postprocessor_config"},"PROCESSOR_POSTPROCESSOR_CONFIG")," JSON under Settings in Dagger creation flow. Multiple Post Processors can be combined in the same configuration and applied to a single Dagger."),(0,o.kt)("h2",{id:"external-post-processor"},"External Post Processor"),(0,o.kt)("p",null,"External Post Processor is the one that connects to an external data source to fetch data in an async manner and perform enrichment of the stream message. These kinds of Post Processors use Flink\u2019s API for asynchronous I/O with external data stores. For more details on Flink\u2019s Async I/O find the doc ",(0,o.kt)("a",{parentName:"p",href:"https://ci.apache.org/projects/flink/flink-docs-release-1.9/dev/stream/operators/asyncio.html"},"here"),"."),(0,o.kt)("p",null,"Currently, we are supporting four external sources."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#elasticsearch"},"Elasticsearch")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#http"},"HTTP")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#postgres"},"Postgres")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#grpc"},"GRPC"))),(0,o.kt)("h3",{id:"elasticsearch"},(0,o.kt)("strong",{parentName:"h3"},"Elasticsearch")),(0,o.kt)("p",null,"This allows you to enrich your data stream with the data on any remote ",(0,o.kt)("a",{parentName:"p",href:"https://www.elastic.co/"},"Elasticsearch"),". For example, let's say you have payment transaction logs in the input stream but user profile information in Elasticsearch, then you can use this post processor to get the profile information in each record."),(0,o.kt)("h4",{id:"workflow"},"Workflow"),(0,o.kt)("p",null,"On applying only this post processor, dagger will perform the following operations on a single message in happy path"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Consume the message from configured Kafka stream."),(0,o.kt)("li",{parentName:"ul"},"Apply the SQL query configured."),(0,o.kt)("li",{parentName:"ul"},"Generate the endpoint URL using ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#endpoint_pattern"},"endpoint_pattern")," and ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#endpoint_variables"},"endpoint_variables"),"."),(0,o.kt)("li",{parentName:"ul"},"Make the Elasticsearch call."),(0,o.kt)("li",{parentName:"ul"},"Read the response from Elasticsearch and populate the message according to ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#output_mapping"},"output_mapping"),"."),(0,o.kt)("li",{parentName:"ul"},"Push the enriched message to configured sink.")),(0,o.kt)("h4",{id:"configuration"},"Configuration"),(0,o.kt)("p",null,"Following variables need to be configured as part of ",(0,o.kt)("a",{parentName:"p",href:"/dagger/docs/reference/configuration#processor_postprocessor_config"},"PROCESSOR_POSTPROCESSOR_CONFIG")," JSON"),(0,o.kt)("h5",{id:"host"},(0,o.kt)("inlineCode",{parentName:"h5"},"host")),(0,o.kt)("p",null,"IP(s) of the nodes/haproxy."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"localhost")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"port"},(0,o.kt)("inlineCode",{parentName:"h5"},"port")),(0,o.kt)("p",null,"Port exposed for the same."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"9200")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"user"},(0,o.kt)("inlineCode",{parentName:"h5"},"user")),(0,o.kt)("p",null,"Username for Elasticsearch."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"testuser")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional"))),(0,o.kt)("h5",{id:"password"},(0,o.kt)("inlineCode",{parentName:"h5"},"password")),(0,o.kt)("p",null,"Password for Elasticsearch."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"test")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional"))),(0,o.kt)("h5",{id:"endpoint_pattern"},(0,o.kt)("inlineCode",{parentName:"h5"},"endpoint_pattern")),(0,o.kt)("p",null,"String template for the endpoint. This will be appended to the host to create the final URL."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"/customers/customer/%s")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"endpoint_variables"},(0,o.kt)("inlineCode",{parentName:"h5"},"endpoint_variables")),(0,o.kt)("p",null,"Comma-separated list of variables used for populating identifiers in endpoint_pattern."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"customer_id")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional"))),(0,o.kt)("h5",{id:"retain_response_type"},(0,o.kt)("inlineCode",{parentName:"h5"},"retain_response_type")),(0,o.kt)("p",null,"If true it will not cast the response from ES to output proto schema. The default behaviour is to cast the response to the output proto schema."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"false")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional")),(0,o.kt)("li",{parentName:"ul"},"Default value: ",(0,o.kt)("inlineCode",{parentName:"li"},"false"))),(0,o.kt)("h5",{id:"retry_timeout"},(0,o.kt)("inlineCode",{parentName:"h5"},"retry_timeout")),(0,o.kt)("p",null,"Timeout between request retries in ms."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"5000")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"socket_timeout"},(0,o.kt)("inlineCode",{parentName:"h5"},"socket_timeout")),(0,o.kt)("p",null,"The time waiting for data after establishing the connection in ms; maximum time of inactivity between two data packets."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"6000")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"connect_timeout"},(0,o.kt)("inlineCode",{parentName:"h5"},"connect_timeout")),(0,o.kt)("p",null,"The timeout value for ES client in ms."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"5000")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"capacity"},(0,o.kt)("inlineCode",{parentName:"h5"},"capacity")),(0,o.kt)("p",null,"This parameter(Async I/O capacity) defines how many max asynchronous requests may be in progress at the same time."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"30")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"output_mapping"},(0,o.kt)("inlineCode",{parentName:"h5"},"output_mapping")),(0,o.kt)("p",null,"Mapping of fields in output Protos goes here. Based on which part of the response data to use, you can configure the path, and output message fields will be populated accordingly. You can use ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/json-path/JsonPath"},"JsonPath")," to select fields from json response."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},'{"customer_profile":{ "path":"$._source"}}')),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"fail_on_errors"},(0,o.kt)("inlineCode",{parentName:"h5"},"fail_on_errors")),(0,o.kt)("p",null,"A flag for deciding whether the job should fail on encountering errors or not. If set false the job won\u2019t fail and enrich with empty fields otherwise the job will fail."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"false")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional")),(0,o.kt)("li",{parentName:"ul"},"Default value: ",(0,o.kt)("inlineCode",{parentName:"li"},"false"))),(0,o.kt)("h5",{id:"metric_id"},(0,o.kt)("inlineCode",{parentName:"h5"},"metric_id")),(0,o.kt)("p",null,"Identifier tag for metrics for every post processor applied. If not given it will use indexes of post processors in the JSON config."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"test_id")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional"))),(0,o.kt)("h4",{id:"sample-query"},"Sample Query"),(0,o.kt)("p",null,"You can select the fields that you want to get from the input stream or you want to use for making the request."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-SQL"},"SELECT customer_id from `booking`\n")),(0,o.kt)("h4",{id:"sample-configuration"},"Sample Configuration"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-properties"},'PROCESSOR_POSTPROCESSOR_ENABLE = true\nPROCESSOR_POSTPROCESSOR_CONFIG = {\n  "external_source": {\n    "es": [\n      {\n        "host": "127.0.0.1",\n        "port": "9200",\n        "endpoint_pattern": "/customers/customer/%s",\n        "endpoint_variables": "customer_id",\n        "retry_timeout": "5000",\n        "socket_timeout": "6000",\n        "stream_timeout": "5000",\n        "connect_timeout": "5000",\n        "capacity": "30",\n        "output_mapping": {\n          "customer_profile": {\n            "path": "$._source"\n          }\n        }\n      }\n    ]\n  }\n}\n')),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Note:")," Though it is subjective to a lot of factors like data in ES, throughput in Kafka, size of ES cluster. A good thumb of rule is to make index call rather than queries to ES for fetching the data."),(0,o.kt)("h3",{id:"http"},(0,o.kt)("strong",{parentName:"h3"},"HTTP")),(0,o.kt)("p",null,"HTTP Post Processor connects to an external API endpoint and does enrichment based on data from the response of the API call. Currently, we support POST and GET verbs for the API call."),(0,o.kt)("h4",{id:"workflow-1"},"Workflow"),(0,o.kt)("p",null,"On applying only this post processor, dagger will perform the following operations on a single message in happy path"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Consume the message from configured Kafka stream."),(0,o.kt)("li",{parentName:"ul"},"Apply the SQL query configured."),(0,o.kt)("li",{parentName:"ul"},"Generate the endpoint URL in case of GET call or request body in case of POST call using ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#request_pattern"},"request_pattern")," and ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#request_variables"},"request_variables"),"."),(0,o.kt)("li",{parentName:"ul"},"Make the HTTP call."),(0,o.kt)("li",{parentName:"ul"},"Read the response from HTTP API and populate the message according to ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#output_mapping-1"},"output_mapping"),"."),(0,o.kt)("li",{parentName:"ul"},"Push the enriched message to configured sink.")),(0,o.kt)("h4",{id:"configuration-1"},"Configuration"),(0,o.kt)("p",null,"Following variables need to be configured as part of ",(0,o.kt)("a",{parentName:"p",href:"/dagger/docs/reference/configuration#processor_postprocessor_config"},"PROCESSOR_POSTPROCESSOR_CONFIG")," JSON"),(0,o.kt)("h5",{id:"endpoint"},(0,o.kt)("inlineCode",{parentName:"h5"},"endpoint")),(0,o.kt)("p",null,"API endpoint. For POST call, URL will be just the endpoint. For GET, URL will be a combination of endpoint and request pattern."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"http://127.0.0.1/api/customer")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"verb"},(0,o.kt)("inlineCode",{parentName:"h5"},"verb")),(0,o.kt)("p",null,"HTTP verb (currently support POST and GET)."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"GET")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"request_pattern"},(0,o.kt)("inlineCode",{parentName:"h5"},"request_pattern")),(0,o.kt)("p",null,"Template for the body in case of POST and endpoint path in case of GET."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"/customers/customer/%s")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"request_variables"},(0,o.kt)("inlineCode",{parentName:"h5"},"request_variables")),(0,o.kt)("p",null,"List of comma-separated parameters to be replaced in request_pattern, these variables must be present in the input proto and selected via the SQL query."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"customer_id")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional"))),(0,o.kt)("h5",{id:"header_pattern"},(0,o.kt)("inlineCode",{parentName:"h5"},"header_pattern")),(0,o.kt)("p",null,"Template for the dynamic headers."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},'{"key": "%s"}')),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional"))),(0,o.kt)("h5",{id:"header_variables"},(0,o.kt)("inlineCode",{parentName:"h5"},"header_variables")),(0,o.kt)("p",null,"List of comma-separated parameters to be replaced in header_pattern, these variables must be present in the input proto and selected via the SQL query."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"customer_id")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional"))),(0,o.kt)("h5",{id:"stream_timeout"},(0,o.kt)("inlineCode",{parentName:"h5"},"stream_timeout")),(0,o.kt)("p",null,"The timeout value for the stream in ms."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"5000")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"connect_timeout-1"},(0,o.kt)("inlineCode",{parentName:"h5"},"connect_timeout")),(0,o.kt)("p",null,"The timeout value for HTTP client in ms."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"5000")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"fail_on_errors-1"},(0,o.kt)("inlineCode",{parentName:"h5"},"fail_on_errors")),(0,o.kt)("p",null,"A flag for deciding whether the job should fail on encountering errors(timeout and status codes apart from 2XX) or not. If set false the job won\u2019t fail and enrich with empty fields otherwise the job will fail."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"false")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional")),(0,o.kt)("li",{parentName:"ul"},"Default value: ",(0,o.kt)("inlineCode",{parentName:"li"},"false"))),(0,o.kt)("h5",{id:"capacity-1"},(0,o.kt)("inlineCode",{parentName:"h5"},"capacity")),(0,o.kt)("p",null,"This parameter(Async I/O capacity) defines how many max asynchronous requests may be in progress at the same time."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"30")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"headers"},(0,o.kt)("inlineCode",{parentName:"h5"},"headers")),(0,o.kt)("p",null,"Key-value pairs for adding headers to the request."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},'{"content-type": "application/json"}')),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional"))),(0,o.kt)("h5",{id:"retain_response_type-1"},(0,o.kt)("inlineCode",{parentName:"h5"},"retain_response_type")),(0,o.kt)("p",null,"If true it will not cast the response from HTTP to output proto schema. The default behaviour is to cast the response to the output proto schema."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"false")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional")),(0,o.kt)("li",{parentName:"ul"},"Default value: ",(0,o.kt)("inlineCode",{parentName:"li"},"false"))),(0,o.kt)("h5",{id:"output_mapping-1"},(0,o.kt)("inlineCode",{parentName:"h5"},"output_mapping")),(0,o.kt)("p",null,"Mapping for all the fields we need to populate from the API response providing a path to fetch the required field from the response body. You can use ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/json-path/JsonPath"},"JsonPath")," to select fields from json response."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},'{"customer_profile":{ "path":"$._source"}}')),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"metric_id-1"},(0,o.kt)("inlineCode",{parentName:"h5"},"metric_id")),(0,o.kt)("p",null,"Identifier tag for metrics for every post processor applied. If not given it will use indexes of post processors in the JSON config."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"test_id")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional"))),(0,o.kt)("h4",{id:"sample-query-1"},"Sample Query"),(0,o.kt)("p",null,"You can select the fields that you want to get from the input stream or you want to use for making the request."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-SQL"},"SELECT customer_id from `booking`\n")),(0,o.kt)("h4",{id:"sample-configuration-for-get"},"Sample Configuration for GET"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-properties"},'PROCESSOR_POSTPROCESSOR_ENABLE = true\nPROCESSOR_POSTPROCESSOR_CONFIG = {\n  "external_source": {\n    "http": [\n      {\n        "endpoint": "http://127.0.0.1",\n        "verb": "get",\n        "request_pattern": "/customers/customer/%s",\n        "request_variables": "customer_id",\n        "header_pattern": "{\\"Header_Key\\": \\"%s\\"}",\n        "header_variables": "wallet_id",\n        "stream_timeout": "5000",\n        "connect_timeout": "5000",\n        "fail_on_errors": "false",\n        "capacity": "30",\n        "headers": {\n          "content-type": "application/json"\n        },\n        "output_mapping": {\n          "customer_profile": {\n            "path": "$._source"\n          }\n        }\n      }\n    ]\n  }\n}\n')),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Note:")," In case you want to use all the fields along with a modified/nested field you can use \u201cselect ","*",", modified_field as custom_column_name from data_stream\u201d."),(0,o.kt)("h4",{id:"sample-configuration-for-post"},"Sample Configuration for POST"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-properties"},'PROCESSOR_POSTPROCESSOR_ENABLE = true\nPROCESSOR_POSTPROCESSOR_CONFIG = {\n  "external_source": {\n    "http": [\n      {\n        "endpoint": "http://127.0.0.1/customer",\n        "verb": "post",\n        "request_pattern": "{\'key\': \\"%s\\"}",\n        "request_variables": "customer_id",\n        "stream_timeout": "5000",\n        "connect_timeout": "5000",\n        "fail_on_errors": "false",\n        "capacity": "30",\n        "headers": {\n          "content-type": "application/json"\n        },\n        "output_mapping": {\n          "test_field": {\n            "path": "$._source"\n          }\n        }\n      }\n    ]\n  }\n}\n')),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Note:")," Post request patterns support both primitive and complex data types. But for complex objects, you need to remove the quotes from the selector ( ",(0,o.kt)("inlineCode",{parentName:"p"},"%s"),"). So in the case of a primitive datapoint of string the selector will be (",(0,o.kt)("inlineCode",{parentName:"p"},"\u201d%s\u201d"),") whereas for complex fields it will be (",(0,o.kt)("inlineCode",{parentName:"p"},"%s"),")."),(0,o.kt)("h3",{id:"postgres"},(0,o.kt)("strong",{parentName:"h3"},"Postgres")),(0,o.kt)("p",null,"This allows you to enrich your data stream with the data on any remote ",(0,o.kt)("a",{parentName:"p",href:"https://www.postgresql.org"},"Postgres"),". For example, let's say you have payment transaction logs in the input stream but user profile information in Postgres, then you can use this post processor to get the profile information in each record. Currently, we support enrichment from PostgresDB queries that result in a single row from DB."),(0,o.kt)("h4",{id:"workflow-2"},"Workflow"),(0,o.kt)("p",null,"On applying only this post processor, dagger will perform the following operations on a single message in happy path"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Consume the message from configured Kafka stream."),(0,o.kt)("li",{parentName:"ul"},"Apply the SQL query configured."),(0,o.kt)("li",{parentName:"ul"},"Generate the Postgres query using ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#query_pattern"},"query_pattern")," and ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#query_variables"},"query_variables"),"."),(0,o.kt)("li",{parentName:"ul"},"Make the Postgres call."),(0,o.kt)("li",{parentName:"ul"},"Read the response from Postgres and populate the message according to ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#output_mapping-2"},"output_mapping"),"."),(0,o.kt)("li",{parentName:"ul"},"Push the enriched message to configured sink.")),(0,o.kt)("h4",{id:"configuration-2"},"Configuration"),(0,o.kt)("p",null,"Following variables need to be configured as part of ",(0,o.kt)("a",{parentName:"p",href:"/dagger/docs/reference/configuration#processor_postprocessor_config"},"PROCESSOR_POSTPROCESSOR_CONFIG")," JSON"),(0,o.kt)("h5",{id:"host-1"},(0,o.kt)("inlineCode",{parentName:"h5"},"host")),(0,o.kt)("p",null,"IP(s) of the nodes/haproxy."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"http://127.0.0.1")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"port-1"},(0,o.kt)("inlineCode",{parentName:"h5"},"port")),(0,o.kt)("p",null,"Port exposed for the same."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"5432")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"user-1"},(0,o.kt)("inlineCode",{parentName:"h5"},"user")),(0,o.kt)("p",null,"Username for Postgres."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"testuser")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"password-1"},(0,o.kt)("inlineCode",{parentName:"h5"},"password")),(0,o.kt)("p",null,"Password for the particular user."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"test")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"database"},(0,o.kt)("inlineCode",{parentName:"h5"},"database")),(0,o.kt)("p",null,"Postgres database name."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"testdb")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"query_pattern"},(0,o.kt)("inlineCode",{parentName:"h5"},"query_pattern")),(0,o.kt)("p",null,"SQL query pattern to populate the data from PostgresDB."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"select email, phone from public.customers where customer_id = '%s'")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"query_variables"},(0,o.kt)("inlineCode",{parentName:"h5"},"query_variables")),(0,o.kt)("p",null,"This is a comma-separated list (without any whitespaces in between) of parameters to be replaced in the query_pattern, and these variables must be present in the input proto."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"customer_id")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional"))),(0,o.kt)("h5",{id:"stream_timeout-1"},(0,o.kt)("inlineCode",{parentName:"h5"},"stream_timeout")),(0,o.kt)("p",null,"The timeout value for the stream in ms."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"25000")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"idle_timeout"},(0,o.kt)("inlineCode",{parentName:"h5"},"idle_timeout")),(0,o.kt)("p",null,"The timeout value for Postgres connection in ms."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"25000")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"connect_timeout-2"},(0,o.kt)("inlineCode",{parentName:"h5"},"connect_timeout")),(0,o.kt)("p",null,"The timeout value for client in ms."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"25000")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"fail_on_errors-2"},(0,o.kt)("inlineCode",{parentName:"h5"},"fail_on_errors")),(0,o.kt)("p",null,"A flag for deciding whether the job should fail on encountering errors or not. If set false the job won\u2019t fail and enrich with empty fields otherwise the job will fail."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"false")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional")),(0,o.kt)("li",{parentName:"ul"},"Default value: ",(0,o.kt)("inlineCode",{parentName:"li"},"false"))),(0,o.kt)("h5",{id:"capacity-2"},(0,o.kt)("inlineCode",{parentName:"h5"},"capacity")),(0,o.kt)("p",null,"This parameter(Async I/O capacity) defines how many max asynchronous requests may be in progress at the same time."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"30")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"retain_response_type-2"},(0,o.kt)("inlineCode",{parentName:"h5"},"retain_response_type")),(0,o.kt)("p",null,"If true it will not cast the response from Postgres Query to output proto schema. The default behaviour is to cast the response to the output proto schema."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"false")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional")),(0,o.kt)("li",{parentName:"ul"},"Default value: ",(0,o.kt)("inlineCode",{parentName:"li"},"false"))),(0,o.kt)("h5",{id:"output_mapping-2"},(0,o.kt)("inlineCode",{parentName:"h5"},"output_mapping")),(0,o.kt)("p",null,"Mapping of fields in output proto goes here. Based on which part of the response data to use, you can configure the path, and output message fields will be populated accordingly."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},'{"customer_email": "email","customer_phone": "phone\u201d}')),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"metric_id-2"},(0,o.kt)("inlineCode",{parentName:"h5"},"metric_id")),(0,o.kt)("p",null,"Identifier tag for metrics for every post processor applied. If not given it will use indexes of post processors in the JSON config."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"test_id")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional"))),(0,o.kt)("h4",{id:"sample-query-2"},"Sample Query"),(0,o.kt)("p",null,"You can select the fields that you want to get from the input stream or you want to use for making the request."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-SQL"},"SELECT customer_id from `booking`\n")),(0,o.kt)("h4",{id:"sample-configuration-1"},"Sample Configuration"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-properties"},'PROCESSOR_POSTPROCESSOR_ENABLE = true\nPROCESSOR_POSTPROCESSOR_CONFIG = {\n  "external_source": {\n    "pg": [\n      {\n        "host": "http://127.0.0.1",\n        "port": "5432",\n        "user": "test",\n        "password": "test",\n        "database": "my_db",\n        "capacity": "30",\n        "stream_timeout": "25000",\n        "connect_timeout": "25000",\n        "idle_timeout": "25000",\n        "query_pattern": "select email, phone from public.customers where customer_id = \'%s\'",\n        "query_variables": "customer_id",\n        "output_mapping": {\n            "customer_email": "email",\n            "customer_phone": "phone\u201d\n        },\n        "fail_on_errors": "true"\n      }\n    ]\n  }\n}\n')),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Note:")," If you want to use % as a special character in your Postgres query, you\u2019ll need to provide an additional % with it as an escape character so that Java doesn\u2019t take it as a string formatter and try to format it, which in turn might end up in invalid format exception.\nE.g. \"select email, phone from public.customers where name like '%%smith'\""),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Note:")," Please add relevant indexing in the database to ensure adequate performance."),(0,o.kt)("h3",{id:"grpc"},(0,o.kt)("strong",{parentName:"h3"},"GRPC")),(0,o.kt)("p",null,"This enables you to enrich the input streams with any information available via remote ",(0,o.kt)("a",{parentName:"p",href:"https://grpc.io/"},"gRPC")," server. For example let's say you have payment transaction logs in the input stream but user profile information available via a gRPC service, then you can use this post processor to get the profile information in each record. Currently, we support only Unary calls."),(0,o.kt)("h4",{id:"workflow-3"},"Workflow"),(0,o.kt)("p",null,"On applying only this post processor, dagger will perform the following operations on a single message in happy path"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Consume the message from configured Kafka stream."),(0,o.kt)("li",{parentName:"ul"},"Apply the SQL query configured."),(0,o.kt)("li",{parentName:"ul"},"Generate the gRPC request using ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#request_pattern-1"},"request_pattern")," and ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#request_variables-1"},"request_variables"),"."),(0,o.kt)("li",{parentName:"ul"},"Make the gRPC call."),(0,o.kt)("li",{parentName:"ul"},"Read the response from gRPC API and populate the message according to ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#output_mapping-3"},"output_mapping"),"."),(0,o.kt)("li",{parentName:"ul"},"Push the enriched message to configured sink.")),(0,o.kt)("h4",{id:"configuration-3"},"Configuration"),(0,o.kt)("p",null,"Following variables need to be configured as part of ",(0,o.kt)("a",{parentName:"p",href:"/dagger/docs/reference/configuration#processor_postprocessor_config"},"PROCESSOR_POSTPROCESSOR_CONFIG")," JSON"),(0,o.kt)("h5",{id:"endpoint-1"},(0,o.kt)("inlineCode",{parentName:"h5"},"endpoint")),(0,o.kt)("p",null,"Hostname of the gRPC endpoint."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"localhost")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"service_port"},(0,o.kt)("inlineCode",{parentName:"h5"},"service_port")),(0,o.kt)("p",null,"Port exposed for the service."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"5000")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"grpc_stencil_url"},(0,o.kt)("inlineCode",{parentName:"h5"},"grpc_stencil_url")),(0,o.kt)("p",null,"Endpoint where request and response proto descriptors are present. If not there, it will try to find from the given stencil_url of the input and output proto of Dagger."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"http://localhost:9000/proto-descriptors/latest")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional"))),(0,o.kt)("h5",{id:"grpc_request_proto_schema"},(0,o.kt)("inlineCode",{parentName:"h5"},"grpc_request_proto_schema")),(0,o.kt)("p",null,"Proto schema for the request for the gRPC endpoint."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"io.grpc.test.Request")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"grpc_response_proto_schema"},(0,o.kt)("inlineCode",{parentName:"h5"},"grpc_response_proto_schema")),(0,o.kt)("p",null,"Proto schema for the response from the gRPC endpoint."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"io.grpc.test.Response")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"grpc_method_url"},(0,o.kt)("inlineCode",{parentName:"h5"},"grpc_method_url")),(0,o.kt)("p",null,"Url of the gRPC method exposed."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"testserver.test/ReturnResponse")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"request_pattern-1"},(0,o.kt)("inlineCode",{parentName:"h5"},"request_pattern")),(0,o.kt)("p",null,"JSON Pattern for the request."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"{'key': %s}")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"request_variables-1"},(0,o.kt)("inlineCode",{parentName:"h5"},"request_variables")),(0,o.kt)("p",null,"This is a comma-separated list of parameters to be replaced in the request_pattern, and these variables must be present in the input proto."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"customer_id")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional"))),(0,o.kt)("h5",{id:"stream_timeout-2"},(0,o.kt)("inlineCode",{parentName:"h5"},"stream_timeout")),(0,o.kt)("p",null,"The timeout value for the stream in ms."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"5000")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"connect_timeout-3"},(0,o.kt)("inlineCode",{parentName:"h5"},"connect_timeout")),(0,o.kt)("p",null,"The timeout value for gRPC client in ms."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"5000")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"fail_on_errors-3"},(0,o.kt)("inlineCode",{parentName:"h5"},"fail_on_errors")),(0,o.kt)("p",null,"A flag for deciding whether the job should fail on encountering errors or not. If set false the job won\u2019t fail and enrich with empty fields otherwise the job will fail."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"false")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional")),(0,o.kt)("li",{parentName:"ul"},"Default value: ",(0,o.kt)("inlineCode",{parentName:"li"},"false"))),(0,o.kt)("h5",{id:"capacity-3"},(0,o.kt)("inlineCode",{parentName:"h5"},"capacity")),(0,o.kt)("p",null,"This parameter(Async I/O capacity) defines how many asynchronous requests may be in progress at the same time."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"30")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"headers-1"},(0,o.kt)("inlineCode",{parentName:"h5"},"headers")),(0,o.kt)("p",null,"Key-value pairs for adding headers to the request."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"{'key': 'value'}")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional"))),(0,o.kt)("h5",{id:"retain_response_type-3"},(0,o.kt)("inlineCode",{parentName:"h5"},"retain_response_type")),(0,o.kt)("p",null,"If true it will not cast the response from gRPC endpoint to output proto schema. The default behaviour is to cast the response to the output proto schema."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"false")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional")),(0,o.kt)("li",{parentName:"ul"},"Default value: ",(0,o.kt)("inlineCode",{parentName:"li"},"false"))),(0,o.kt)("h5",{id:"output_mapping-3"},(0,o.kt)("inlineCode",{parentName:"h5"},"output_mapping")),(0,o.kt)("p",null,"Mapping of fields in output proto goes here. Based on which part of the response data to use, you can configure the path, and output message fields will be populated accordingly. You can use ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/json-path/JsonPath"},"JsonPath")," to select fields from json response."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},'{"customer_profile":{ "path":"$._source"}}')),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h5",{id:"metric_id-3"},(0,o.kt)("inlineCode",{parentName:"h5"},"metric_id")),(0,o.kt)("p",null,"Identifier tag for metrics for every post processor applied. If not given it will use indexes of post processors in the JSON config."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"test_id")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional"))),(0,o.kt)("h4",{id:"sample-query-3"},"Sample Query"),(0,o.kt)("p",null,"You can select the fields that you want to get from the input stream or you want to use for making the request."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-SQL"},"SELECT customer_id from `booking`\n")),(0,o.kt)("h4",{id:"sample-configuration-2"},"Sample Configuration"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-properties"},'PROCESSOR_POSTPROCESSOR_ENABLE = true\nPROCESSOR_POSTPROCESSOR_CONFIG = {\n  "external_source": {\n    "grpc": [\n      {\n        "endpoint": "localhost",\n        "service_port": "5000",\n        "request_pattern": "{\'key\': %s}",\n        "request_variables": "customer_id",\n        "grpc_stencil_url": "http://localhost:9000/proto-descriptors/latest",\n        "grpc_request_proto_schema": "io.grpc.test.Request",\n        "grpc_response_proto_schema": "io.grpc.test.Response",\n        "grpc_method_url": "testserver.test/ReturnResponse",\n        "stream_timeout": "5000",\n        "connect_timeout": "5000",\n        "fail_on_errors": "false",\n        "capacity": "30",\n        "headers": {\n          "key": "value"\n        },\n        "output_mapping": {\n          "customer_profile": {\n            "path": "$._source"\n          }\n        }\n      }\n    ]\n  }\n}\n')),(0,o.kt)("h2",{id:"internal-post-processor"},"Internal Post Processor"),(0,o.kt)("p",null,"In order to enhance output with data that doesn\u2019t need an external data store, you can use this configuration. At present, we support 3 types."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"SQL"),": Data fields from the SQL query output. You could either use a specific field or ",(0,o.kt)("inlineCode",{parentName:"li"},"*")," for all the fields. In case of selecting ",(0,o.kt)("inlineCode",{parentName:"li"},"*")," you have the option to either map all fields to single output field or multiple output fields with the same name. Check the example in ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#sample-configurations"},"sample configuration"),"."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Constant"),": Constant value without any transformation."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Function"),": Predefined functions (in Dagger) which will be evaluated at the time of event processing. At present, we support only the following 2 functions:",(0,o.kt)("ol",{parentName:"li"},(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"CURRENT_TIMESTAMP"),", which can be used to populate the latest timestamp."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"JSON_PAYLOAD"),", which can be used to get the entire incoming proto message as a JSON string. For this function to work correctly, ensure that the Dagger SQL outputs rows in the same format as the proto class specified in ",(0,o.kt)("inlineCode",{parentName:"li"},"internal_processor_config")," field (check the function example in ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#sample-configurations"},"sample configuration"),").")))),(0,o.kt)("h3",{id:"workflow-4"},"Workflow"),(0,o.kt)("p",null,"On applying only this post processor, dagger will perform the following operations on a single message in happy path"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Consume the message from configured Kafka stream."),(0,o.kt)("li",{parentName:"ul"},"Apply the SQL query configured."),(0,o.kt)("li",{parentName:"ul"},"Populate the provided ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#output_field"},"output_field")," with the ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#value"},"value")," depending upon the ",(0,o.kt)("a",{parentName:"li",href:"/dagger/docs/advance/post_processor#type"},"type"),"."),(0,o.kt)("li",{parentName:"ul"},"Push the populated message to configured sink.")),(0,o.kt)("h3",{id:"configuration-4"},"Configuration"),(0,o.kt)("p",null,"Following variables need to be configured as part of ",(0,o.kt)("a",{parentName:"p",href:"/dagger/docs/reference/configuration#processor_postprocessor_config"},"PROCESSOR_POSTPROCESSOR_CONFIG")," JSON"),(0,o.kt)("h4",{id:"output_field"},(0,o.kt)("inlineCode",{parentName:"h4"},"output_field")),(0,o.kt)("p",null,"The field in output proto where this field should be populated."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"event_timestamp")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h4",{id:"value"},(0,o.kt)("inlineCode",{parentName:"h4"},"value")),(0,o.kt)("p",null,"The input data."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"CURRENT_TIMESTAMP")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h4",{id:"type"},(0,o.kt)("inlineCode",{parentName:"h4"},"type")),(0,o.kt)("p",null,"The type of internal post processor. This could be \u2018SQL\u2019, \u2018constant\u2019 or \u2018function\u2019 as explained above."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},"function")),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"required"))),(0,o.kt)("h4",{id:"internal_processor_config"},(0,o.kt)("inlineCode",{parentName:"h4"},"internal_processor_config")),(0,o.kt)("p",null,"The configuration argument needed to specify inputs for certain function type internal post processors. As of now, this is only required for ",(0,o.kt)("inlineCode",{parentName:"p"},"JSON_PAYLOAD")," internal post processor."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example value: ",(0,o.kt)("inlineCode",{parentName:"li"},'{"schema_proto_class": "io.odpf.dagger.consumer.TestBookingLogMessage"}')),(0,o.kt)("li",{parentName:"ul"},"Type: ",(0,o.kt)("inlineCode",{parentName:"li"},"optional"))),(0,o.kt)("h3",{id:"sample-query-4"},"Sample Query"),(0,o.kt)("p",null,"You can select the fields that you want to get from the input stream or you want to use for making the request."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-SQL"},"SELECT * from `booking`\n")),(0,o.kt)("h3",{id:"sample-configurations"},"Sample Configurations"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"SQL")),(0,o.kt)("p",null,"This configuration will populate field ",(0,o.kt)("inlineCode",{parentName:"p"},"booking_log")," with all the input fields selected in the SQL"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-properties"},'PROCESSOR_POSTPROCESSOR_ENABLE = true\nPROCESSOR_POSTPROCESSOR_CONFIG = {\n  "internal_source": [\n    {\n      "output_field": "booking_log",\n      "type": "sql",\n      "value": "*"\n    }\n  ]\n}\n')),(0,o.kt)("p",null,"In order to select all fields and map them to multiple fields with same name in the output proto"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-properties"},'PROCESSOR_POSTPROCESSOR_ENABLE = true\nPROCESSOR_POSTPROCESSOR_CONFIG = {\n  "internal_source": [\n    {\n      "output_field": "*",\n      "type": "sql",\n      "value": "*"\n    }\n  ]\n}\n')),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Constant")),(0,o.kt)("p",null,"This configuration will populate field ",(0,o.kt)("inlineCode",{parentName:"p"},"s2id_level")," with value 13 for all the events"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-properties"},'PROCESSOR_POSTPROCESSOR_ENABLE = true\nPROCESSOR_POSTPROCESSOR_CONFIG = {\n  "internal_source": [\n    {\n      "output_field": "s2id_level",\n      "type": "constant",\n      "value": "13"\n    }\n  ]\n}\n')),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Function")),(0,o.kt)("p",null,"This configuration will populate field ",(0,o.kt)("inlineCode",{parentName:"p"},"event_timestamp")," with a timestamp of when the event is processed."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-properties"},'FLINK_SQL_QUERY=SELECT * from data_stream\nPROCESSOR_POSTPROCESSOR_ENABLE = true\nPROCESSOR_POSTPROCESSOR_CONFIG = {\n  "internal_source": [\n    {\n      "output_field": "event_timestamp",\n      "type": "function",\n      "value": "CURRENT_TIMESTAMP"\n    }\n  ]\n}\n')),(0,o.kt)("p",null,"Similarly, the following configuration will fill the ",(0,o.kt)("inlineCode",{parentName:"p"},"json_payload")," field with the complete output of SQL query, in JSON format."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-properties"},'FLINK_SQL_QUERY=SELECT * from data_stream\nPROCESSOR_POSTPROCESSOR_ENABLE = true\nPROCESSOR_POSTPROCESSOR_CONFIG = {\n  "internal_source": [\n    {\n      "output_field": "json_payload",\n      "type": "function",\n      "value": "JSON_PAYLOAD",\n      "internal_processor_config": {\n        "schema_proto_class": "io.odpf.dagger.consumer.TestBookingLogMessage"\n      }\n    }\n  ]\n}\n')),(0,o.kt)("h2",{id:"transformers"},"Transformers"),(0,o.kt)("p",null,"Transformers are the type of processors that let users define more complex processing capabilities by writing custom Java code. As this is a vast topic, we have covered it in detail ",(0,o.kt)("a",{parentName:"p",href:"/dagger/docs/guides/use_transformer"},"here"),"."),(0,o.kt)("h1",{id:"post-processor-requirements"},"Post Processor requirements"),(0,o.kt)("p",null,"Some basic information you need to know before the creation of a Post Processor Dagger is as follow"),(0,o.kt)("h2",{id:"number-of-post-processors"},"Number of Post Processors"),(0,o.kt)("p",null,"Any number of post processors can be chained in a single dagger for a given use-case. The post-processors could be of the same or different type. The initial SQL do not depend on the number of Post Processors and you can simply start with selecting as many fields that are required for the final result as well as the Post Processors in the SQL."),(0,o.kt)("h2",{id:"throughput"},"Throughput"),(0,o.kt)("p",null,"The throughput depends on the input topic of Dagger and after SQL filtering, the enrichment store should be able to handle that load."),(0,o.kt)("h2",{id:"output-proto"},"Output Proto"),(0,o.kt)("p",null,"The output proto should have all the fields that you want to output from the input stream as well as fields getting enriched from the Post Processor with the correct data type."),(0,o.kt)("h2",{id:"connectivity"},"Connectivity"),(0,o.kt)("p",null,"The enrichment store should have connectivity to the Dagger deployment."))}d.isMDXComponent=!0},3862:function(e,t,n){t.Z=n.p+"assets/images/external-http-post-processor-058061066d4696892bae0347e772e83a.png"},3471:function(e,t,n){t.Z=n.p+"assets/images/external-internal-post-processor-1f9f631b1a47ddd612b6025734327cc1.png"},4684:function(e,t,n){t.Z=n.p+"assets/images/external-internal-transformer-post-processor-29bac9755b46a267096a2a935f3c773f.png"}}]);